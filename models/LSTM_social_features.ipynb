{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/miniconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input NFT collection names and their floor prices, market volume\n",
    "def nft_market_data(nft_name):\n",
    "    df1 = pd.read_csv(nft_name +'_floor_price.csv')\n",
    "    df2 = pd.read_csv(nft_name +'_market_volume.csv')\n",
    "    market_volume = df2['market_volume'].tolist()\n",
    "    floor_price = df1['floor_price'].tolist()\n",
    "    \n",
    "    floor_price.pop()\n",
    "    market_volume.pop()\n",
    "    return floor_price, market_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def nft_tweets_social_embeddings(nft_name, embedding_name):\n",
    "    average_embeddings = []\n",
    "\n",
    "    start_date = '2022-08-01'\n",
    "    end_date = '2023-02-27'\n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "\n",
    "    for date in date_range:\n",
    "        date_str = date.strftime(\"%Y-%m-%d\")\n",
    "        csv_file = os.path.join(f\"{date_str}.csv\")\n",
    "        embeddings = []\n",
    "        if os.path.exists(csv_file):\n",
    "            df = pd.read_csv(csv_file)\n",
    "            keyword_indices = df[df['Text'].str.contains(nft_name, case=False)].index\n",
    "\n",
    "            daily_embedding_folder = os.path.join(f\"/home/qian/qian/CS6220-NFT-Celebrities-Twitter-Analysis-main/{embedding_name}/{date_str}\")\n",
    "            for index in keyword_indices:\n",
    "                index_file = os.path.join(f\"{daily_embedding_folder}/{index}.npy\")\n",
    "                if os.path.exists(index_file):\n",
    "                    embedding = np.load(index_file)[...,-2:]\n",
    "                    embedding_dim = embedding.shape[0]\n",
    "                    embeddings.append(embedding)\n",
    "\n",
    "            if len(embeddings) > 0:\n",
    "                average_bert_embeddings = np.mean(embeddings, axis=0)\n",
    "            else:\n",
    "                average_bert_embeddings = np.zeros((2,))\n",
    "            average_embeddings.append(average_bert_embeddings)\n",
    "    return average_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input NFT collection names and their floor prices, market volume\n",
    "def nft_market_data(nft_name):\n",
    "    df1 = pd.read_csv(nft_name +'_floor_price.csv')\n",
    "    df2 = pd.read_csv(nft_name +'_market_volume.csv')\n",
    "    market_volume = df2['market_volume'].tolist()\n",
    "    floor_price = df1['floor_price'].tolist()\n",
    "    \n",
    "    floor_price.pop()\n",
    "    market_volume.pop()\n",
    "    return floor_price, market_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test:nft_market_data('azuki')\n",
    "azuki_price, azuki_volume = nft_market_data('azuki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayc\n",
    "bayc_price, bayc_volume = nft_market_data('bayc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayc_price_tensor = torch.tensor(bayc_price, dtype=torch.float32)\n",
    "bayc_volume_tensor = torch.tensor(bayc_volume, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherdeed\n",
    "otherdeed_price, otherdeed_volume = nft_market_data('otherdeed_for_otherside')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clonex\n",
    "clonex_price, clonex_volume = nft_market_data('clonex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clonex tensor\n",
    "clonex_price_tensor = torch.tensor(clonex_price, dtype=torch.float32)\n",
    "clonex_market_volume_tensor = torch.tensor(clonex_volume, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherdeed_price_tensor = torch.tensor(otherdeed_price, dtype=torch.float32)\n",
    "otherdeed_market_volume_tensor = torch.tensor(otherdeed_volume, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mayc\n",
    "mayc_price, mayc_volume = nft_market_data('mayc')\n",
    "mayc_price_tensor = torch.tensor(mayc_price, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "mayc_market_volume_tensor = torch.tensor(mayc_volume, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to tensor\n",
    "azuki_price_tensor = torch.tensor(azuki_price, dtype=torch.float32)\n",
    "azuki_market_volume_tensor = torch.tensor(azuki_volume, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.0000,  8.8980,  8.5103,  8.7980,  8.5000,  8.5000,  8.5000,  8.5000,\n",
      "         7.8000,  7.5000,  7.5000,  8.0500,  7.5000,  6.7000,  6.3000,  6.3000,\n",
      "         7.0000,  7.0000,  7.0000,  6.7000,  5.9900,  5.9000,  5.8000,  6.3500,\n",
      "         6.2500,  7.1000,  8.0000,  8.0000,  8.5000,  7.9900,  7.9900,  8.0000,\n",
      "         7.8600,  8.0000,  8.0000,  7.8880,  7.6000,  7.6000,  7.5000,  6.9500,\n",
      "         7.4900,  7.1000,  6.9000,  6.9000,  7.8000,  8.5000,  8.6900,  8.6900,\n",
      "        10.2500,  9.9500, 10.5000, 10.8000, 11.2000, 10.5000, 10.2900,  9.6900,\n",
      "         9.0330,  8.9900,  9.0000,  9.0000,  9.9700, 10.0000,  9.7000,  9.7000,\n",
      "        10.3800, 10.3800, 10.3000, 10.3000, 10.3000, 10.3000, 10.1900, 10.3000,\n",
      "        10.4000, 10.4900, 10.2500, 10.2000,  9.5000,  9.7000,  9.9500, 11.2500,\n",
      "        11.0200, 11.3500, 11.1000, 11.3500, 11.9500, 11.7204, 11.6129, 10.7200,\n",
      "        10.7200, 11.2800, 11.1900,  3.7754, 10.8000, 10.8000, 10.2000, 10.1633,\n",
      "        10.9694, 10.9000, 10.8000, 10.8000,  9.3878,  9.1837,  8.8800,  9.6700,\n",
      "         9.7000,  8.6633,  9.4880,  9.0000,  9.7900,  9.5000,  9.5000, 10.0000,\n",
      "         9.6000,  9.6500,  9.7200,  9.2847,  9.2755,  9.2755,  9.9000, 10.1939,\n",
      "         9.9900, 10.4000, 10.4000, 10.1939, 10.3776, 10.4100, 11.2000, 11.0204,\n",
      "        11.7041, 11.9900, 11.5000, 11.2245, 11.6800, 11.5900, 11.5000, 11.6837,\n",
      "        11.2143, 11.1633, 11.1633, 11.1122, 10.8890, 10.8890, 11.0612, 10.9694,\n",
      "        11.0102, 11.1230, 11.4300, 11.1000, 11.1000, 11.5000, 11.4000, 11.5000,\n",
      "        11.7347, 12.5500, 11.6300, 11.6300, 11.6300, 11.9900, 14.9000, 14.2500,\n",
      "        14.2300, 12.9900, 12.7890, 13.2857, 15.7653, 15.0000, 12.5000, 12.5000,\n",
      "        13.8800, 13.2700, 13.2700, 14.9900, 14.7900, 14.2000, 12.5000, 12.8900,\n",
      "        12.6900, 12.8900, 12.7900, 12.4890, 12.4890, 13.7755, 13.8000, 13.8000,\n",
      "        13.7480, 13.9000, 13.9000, 13.9000, 13.7857, 13.7900, 13.4900, 13.3900,\n",
      "        13.3900, 12.9100, 12.4900, 12.4900, 12.4000, 12.4900, 14.0000, 12.9000,\n",
      "        14.0816, 14.2800, 14.2857, 14.7000, 14.7900, 14.7900, 15.2300, 14.1000,\n",
      "        14.0000, 14.3000, 14.9000])\n"
     ]
    }
   ],
   "source": [
    "print(azuki_price_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get azuki tweets social embeddings\n",
    "azuki_tweets_social_embeddings = nft_tweets_social_embeddings('azuki', 'bert_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.93333333, 10.12      ]), array([ 0.7804878 , 10.84146341]), array([ 0.65217391, 10.11594203]), array([ 2.24137931, 14.24137931]), array([0.11111111, 3.24444444])]\n"
     ]
    }
   ],
   "source": [
    "# print azuki_tweets_social_embeddings first 5 elements\n",
    "print(azuki_tweets_social_embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bayc tweets social embeddings\n",
    "bayc_tweets_social_embeddings = nft_tweets_social_embeddings('bayc', 'bert_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_bayc_bert_embeddings_tensor = torch.tensor(np.vstack(bayc_tweets_social_embeddings), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert embeddings to a tensor and convert floor prices to a tensor\n",
    "average_azuki_bert_embeddings_tensor = torch.tensor(np.vstack(azuki_tweets_social_embeddings), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9333, 10.1200],\n",
      "        [ 0.7805, 10.8415],\n",
      "        [ 0.6522, 10.1159],\n",
      "        [ 2.2414, 14.2414],\n",
      "        [ 0.1111,  3.2444]])\n"
     ]
    }
   ],
   "source": [
    "# print first 5 embeddings\n",
    "print(average_azuki_bert_embeddings_tensor[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mayc social embeddings\n",
    "mayc_tweets_social_embeddings = nft_tweets_social_embeddings('mayc', 'bert_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert embeddings to a tensor\n",
    "average_mayc_bert_embeddings_tensor = torch.tensor(np.vstack(mayc_tweets_social_embeddings), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherdeed social embeddings\n",
    "otherdeed_tweets_social_embeddings = nft_tweets_social_embeddings('otherdeed_for_otherside', 'bert_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert embeddings to a tensor\n",
    "average_otherdeed_bert_embeddings_tensor = torch.tensor(np.vstack(otherdeed_tweets_social_embeddings), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clonex social embeddings\n",
    "clonex_tweets_social_embeddings = nft_tweets_social_embeddings('clonex', 'bert_embeddings')\n",
    "\n",
    "# convert embeddings to a tensor\n",
    "average_clonex_bert_embeddings_tensor = torch.tensor(np.vstack(clonex_tweets_social_embeddings), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.0289\n",
      "Epoch [2/200], Loss: 0.0279\n",
      "Epoch [3/200], Loss: 0.0058\n",
      "Epoch [4/200], Loss: 0.0180\n",
      "Epoch [5/200], Loss: 0.0234\n",
      "Epoch [6/200], Loss: 0.0131\n",
      "Epoch [7/200], Loss: 0.0110\n",
      "Epoch [8/200], Loss: 0.0203\n",
      "Epoch [9/200], Loss: 0.0251\n",
      "Epoch [10/200], Loss: 0.0242\n",
      "Epoch [11/200], Loss: 0.0112\n",
      "Epoch [12/200], Loss: 0.0267\n",
      "Epoch [13/200], Loss: 0.0087\n",
      "Epoch [14/200], Loss: 0.0089\n",
      "Epoch [15/200], Loss: 0.0982\n",
      "Epoch [16/200], Loss: 0.0081\n",
      "Epoch [17/200], Loss: 0.0127\n",
      "Epoch [18/200], Loss: 0.0264\n",
      "Epoch [19/200], Loss: 0.0167\n",
      "Epoch [20/200], Loss: 0.0745\n",
      "Epoch [21/200], Loss: 0.0122\n",
      "Epoch [22/200], Loss: 0.0116\n",
      "Epoch [23/200], Loss: 0.0063\n",
      "Epoch [24/200], Loss: 0.0107\n",
      "Epoch [25/200], Loss: 0.0130\n",
      "Epoch [26/200], Loss: 0.0274\n",
      "Epoch [27/200], Loss: 0.0140\n",
      "Epoch [28/200], Loss: 0.0122\n",
      "Epoch [29/200], Loss: 0.0091\n",
      "Epoch [30/200], Loss: 0.0160\n",
      "Epoch [31/200], Loss: 0.0752\n",
      "Epoch [32/200], Loss: 0.0889\n",
      "Early stopping at epoch 33\n",
      "Mean Squared Error: 1241668.125\n",
      "Root Mean Squared Error: 1114.3016310676387\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "\n",
    "# Prepare dataset\n",
    "X = average_otherdeed_bert_embeddings_tensor  # Shape: (number_of_dates, 770)\n",
    "y = otherdeed_market_volume_tensor # Shape: (number_of_dates, 1)\n",
    "\n",
    "# Reshape the data before normalization\n",
    "X_numpy = X.numpy()\n",
    "y_numpy = y.numpy().reshape(-1, 1)\n",
    "\n",
    "# Split the dataset into training and test sets, use first 80% of the data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_numpy, y_numpy, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Normalize the input data\n",
    "scaler_X = MinMaxScaler()\n",
    "X_train_normalized = scaler_X.fit_transform(X_train)\n",
    "X_test_normalized = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_normalized = scaler_y.fit_transform(y_train)\n",
    "\n",
    "# Convert the normalized data back to tensors\n",
    "X_train = torch.tensor(X_train_normalized, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_normalized, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_normalized, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 2\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "drop_prob = 0.1\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, drop_prob)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model with early stopping\n",
    "num_epochs = 200\n",
    "early_stop = 30  # Number of epochs to wait before early stopping\n",
    "best_loss = float('inf')\n",
    "best_epoch = 0\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (embeddings, targets) in enumerate(train_loader):\n",
    "        embeddings = embeddings.unsqueeze(1)  # Shape: (batch_size, 1, 770)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        best_epoch = epoch\n",
    "        best_model = model.state_dict()\n",
    "    elif epoch - best_epoch >= early_stop:\n",
    "        print(f'Early stopping at epoch {epoch+1}')\n",
    "        break\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_test = X_test.unsqueeze(1)  # Shape: (test_size, 1, 770)\n",
    "    y_pred_normalized = model(X_test)\n",
    "\n",
    "    # Inverse transform the normalized predictions to get the unnormalized predictions\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_normalized.numpy())\n",
    "\n",
    "# Calculate the mean squared error or any other performance metric\n",
    "mse = criterion(torch.tensor(y_pred), y_test)\n",
    "print('Mean Squared Error:', mse.item())\n",
    "\n",
    "rmse = math.sqrt(mse.item())\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Add some code to document the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
